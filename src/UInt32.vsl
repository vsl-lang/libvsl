// Represents a 32-bit unsigned integer.
@primitive(Integer) @mock(ui32) public class UInt32 {

    @backend(llvm)
    @inline(always)
    public static func +(lhs: UInt32, rhs: UInt32) -> UInt32 native(iadd)

    @backend(llvm)
    @inline(always)
    public static func -(lhs: UInt32, rhs: UInt32) -> UInt32 native(isub)

    @backend(llvm)
    @inline(always)
    public static func *(lhs: UInt32, rhs: UInt32) -> UInt32 native(imul)

    @backend(llvm)
    @inline(always)
    public static func /(lhs: UInt32, rhs: UInt32) -> Double native(uidiv)

    @backend(llvm)
    @inline(always)
    public static func \(lhs: UInt32, rhs: UInt32) -> UInt32 native(udiv)

    @backend(llvm)
    @inline(always)
    public static func %(lhs: UInt32, rhs: UInt32) -> UInt32 native(uirem)

    @backend(llvm)
    @inline(always)
    public static func &(lhs: UInt32, rhs: UInt32) -> UInt32 native(and);

    @backend(llvm)
    @inline(always)
    public static func |(lhs: UInt32, rhs: UInt32) -> UInt32 native(or);

    @backend(llvm)
    @inline(always)
    public static func ^(lhs: UInt32, rhs: UInt32) -> UInt32 native(xor);

    @backend(llvm)
    @inline(always)
    public static func ==(lhs: UInt32, rhs: UInt32) -> Bool native(ieq)

    @backend(llvm)
    @inline(always)
    public static func !=(lhs: UInt32, rhs: UInt32) -> Bool native(ineq)

    @backend(llvm)
    @inline(always)
    public static func >=(lhs: UInt32, rhs: UInt32) -> Bool native(uigte)

    @backend(llvm)
    @inline(always)
    public static func <=(lhs: UInt32, rhs: UInt32) -> Bool native(uilte)

    @backend(llvm)
    @inline(always)
    public static func >(lhs: UInt32, rhs: UInt32) -> Bool native(uigt)

    @backend(llvm)
    @inline(always)
    public static func <(lhs: UInt32, rhs: UInt32) -> Bool native(uilt)

    @backend(llvm)
    @inline(always)
    public static func <<(lhs: UInt32, rhs: UInt32) -> UInt32 native(shl);

    @backend(llvm)
    @inline(always)
    public static func >>(lhs: UInt32, rhs: UInt32) -> UInt32 native(ashr);

    @backend(llvm)
    @inline(always)
    public static func >>>(lhs: UInt32, rhs: UInt32) -> Int8 native(lshr);

    @backend(llvm)
    @inline(always)
    public static func ~(expression: UInt32) -> UInt32 native(inot)

    @backend(llvm)
    @inline(always)
    public static func -(expression: UInt32) -> UInt32 native(ineg)

    /// Converts to string
    func toString(base: Int = 10) -> String {
        assert(base > 0, "UInt32#toString(base:): base must be positive")
        assert(base <= 26, "UInt32#toString(base:): base must be at most 26")

        let length: UInt64 = UInt64::floor(log(Double::self)/log(Double::base)) + 1

        const stringBytes = Pointer<UInt8>.alloc(count: length + 1)
        let stringPos = stringBytes.offset(by: Int64::length - 1)

        let n: UInt32 = self

        do {
            let digit = n % UInt32::base

            if digit < 0x0A {
                // 48 is char code for '0'
                stringPos.store(value: 48 + UInt8::digit)
            } else {
                // 65 is char code for 'A'
                stringPos.store(value: 65 + UInt8::digit - 0x0A)
            }

            stringPos = stringPos.offset(by: -1)
        } while (n \= UInt32::base) != 0

        // Store suffix null byte
        stringBytes.offset(by: Int64::length).store(value: 0)

        return String(value: stringBytes, byteLength: UInt::length)
    }

    /// Generates random number in range [from, to)
    public static func random(from start: UInt32, to end: UInt32) -> UInt32 {
        assert(end > start, "Random end must be greater than start")
        return (UInt32::getRandomInt()) % (end - start) + start
    }

    /// Smallest possible
    public static const minValue: UInt32 = 0

    /// Largest possible
    public static const maxValue: UInt32 = ~0
}

public typealias UInt = UInt32
